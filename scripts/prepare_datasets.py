#!/usr/bin/env python3
"""
Prepare datasets for Gemma-3 270M glyph training
Creates three core datasets:
1. glyph_sequences.jsonl - Real Unicode/emoji sequences
2. glyph_compose.jsonl - Composition instructions
3. glyph_tags.jsonl - Glyph to semantic tags mapping
"""

import json
import random
from pathlib import Path
from typing import List, Dict, Tuple
import unicodedata

# Common emoji categories
EMOJI_CATEGORIES = {
    'emotions': ['ðŸ˜€', 'ðŸ˜ƒ', 'ðŸ˜„', 'ðŸ˜', 'ðŸ˜Š', 'ðŸ¥°', 'ðŸ˜', 'ðŸ¤©', 'ðŸ˜˜', 'ðŸ˜—', 'â˜ºï¸', 'ðŸ˜š', 'ðŸ˜™', 'ðŸ¥²', 'ðŸ˜‹', 'ðŸ˜›', 'ðŸ˜œ', 'ðŸ¤ª', 'ðŸ˜', 'ðŸ¤‘', 'ðŸ¤—', 'ðŸ¤­', 'ðŸ«¢', 'ðŸ«£', 'ðŸ¤«', 'ðŸ¤”', 'ðŸ«¡', 'ðŸ¤', 'ðŸ¤¨', 'ðŸ˜', 'ðŸ˜‘', 'ðŸ˜¶', 'ðŸ«¥', 'ðŸ˜', 'ðŸ˜’', 'ðŸ™„', 'ðŸ˜¬', 'ðŸ˜®â€ðŸ’¨', 'ðŸ¤¥', 'ðŸ˜Œ', 'ðŸ˜”', 'ðŸ˜ª', 'ðŸ¤¤', 'ðŸ˜´', 'ðŸ˜·', 'ðŸ¤’', 'ðŸ¤•', 'ðŸ¤¢', 'ðŸ¤®', 'ðŸ¤§', 'ðŸ¥µ', 'ðŸ¥¶', 'ðŸ¥´', 'ðŸ˜µ', 'ðŸ˜µâ€ðŸ’«', 'ðŸ¤¯', 'ðŸ¤ ', 'ðŸ¥³', 'ðŸ¥¸', 'ðŸ˜Ž', 'ðŸ¤“', 'ðŸ§', 'ðŸ˜•', 'ðŸ«¤', 'ðŸ˜Ÿ', 'ðŸ™', 'â˜¹ï¸', 'ðŸ˜®', 'ðŸ˜¯', 'ðŸ˜²', 'ðŸ˜³', 'ðŸ¥º', 'ðŸ¥¹', 'ðŸ˜¦', 'ðŸ˜§', 'ðŸ˜¨', 'ðŸ˜°', 'ðŸ˜¥', 'ðŸ˜¢', 'ðŸ˜­', 'ðŸ˜±', 'ðŸ˜–', 'ðŸ˜£', 'ðŸ˜ž', 'ðŸ˜“', 'ðŸ˜©', 'ðŸ˜«', 'ðŸ¥±', 'ðŸ˜¤', 'ðŸ˜¡', 'ðŸ˜ ', 'ðŸ¤¬', 'ðŸ˜ˆ', 'ðŸ‘¿', 'ðŸ’€', 'â˜ ï¸', 'ðŸ’©', 'ðŸ¤¡', 'ðŸ‘¹', 'ðŸ‘º', 'ðŸ‘»', 'ðŸ‘½', 'ðŸ‘¾', 'ðŸ¤–'],
    'hearts': ['â¤ï¸', 'ðŸ§¡', 'ðŸ’›', 'ðŸ’š', 'ðŸ’™', 'ðŸ’œ', 'ðŸ–¤', 'ðŸ¤', 'ðŸ¤Ž', 'â¤ï¸â€ðŸ”¥', 'â¤ï¸â€ðŸ©¹', 'ðŸ’”', 'â£ï¸', 'ðŸ’•', 'ðŸ’ž', 'ðŸ’“', 'ðŸ’—', 'ðŸ’–', 'ðŸ’˜', 'ðŸ’', 'ðŸ’Ÿ', 'â˜®ï¸', 'âœï¸', 'â˜ªï¸', 'ðŸ•‰ï¸', 'â˜¸ï¸', 'âœ¡ï¸', 'ðŸ”¯', 'ðŸ•Ž', 'â˜¯ï¸', 'â˜¦ï¸', 'ðŸ›', 'â›Ž', 'â™ˆ', 'â™‰', 'â™Š', 'â™‹', 'â™Œ', 'â™', 'â™Ž', 'â™', 'â™', 'â™‘', 'â™’', 'â™“', 'ðŸ†”', 'âš›ï¸', 'ðŸ‰‘', 'â˜¢ï¸', 'â˜£ï¸', 'ðŸ“´', 'ðŸ“³', 'ðŸˆ¶', 'ðŸˆš', 'ðŸˆ¸', 'ðŸˆº', 'ðŸˆ·ï¸', 'âœ´ï¸', 'ðŸ†š', 'ðŸ’®', 'ðŸ‰', 'ãŠ™ï¸', 'ãŠ—ï¸', 'ðŸˆ´', 'ðŸˆµ', 'ðŸˆ¹', 'ðŸˆ²', 'ðŸ…°ï¸', 'ðŸ…±ï¸', 'ðŸ†Ž', 'ðŸ†‘', 'ðŸ…¾ï¸', 'ðŸ†˜'],
    'nature': ['ðŸŒ¸', 'ðŸ’®', 'ðŸµï¸', 'ðŸŒ¹', 'ðŸ¥€', 'ðŸŒº', 'ðŸŒ»', 'ðŸŒ¼', 'ðŸŒ·', 'ðŸŒ±', 'ðŸª´', 'ðŸŒ²', 'ðŸŒ³', 'ðŸŒ´', 'ðŸŒµ', 'ðŸŒ¾', 'ðŸŒ¿', 'â˜˜ï¸', 'ðŸ€', 'ðŸ', 'ðŸ‚', 'ðŸƒ', 'ðŸª¹', 'ðŸªº', 'ðŸ„', 'ðŸš', 'ðŸª¸', 'ðŸª¨', 'ðŸŒ‘', 'ðŸŒ’', 'ðŸŒ“', 'ðŸŒ”', 'ðŸŒ•', 'ðŸŒ–', 'ðŸŒ—', 'ðŸŒ˜', 'ðŸŒ™', 'ðŸŒš', 'ðŸŒ›', 'ðŸŒœ', 'â˜€ï¸', 'ðŸŒ', 'ðŸŒž', 'â­', 'ðŸŒŸ', 'ðŸŒ ', 'â˜ï¸', 'â›…', 'â›ˆï¸', 'ðŸŒ¤ï¸', 'ðŸŒ¥ï¸', 'ðŸŒ¦ï¸', 'ðŸŒ§ï¸', 'ðŸŒ¨ï¸', 'ðŸŒ©ï¸', 'ðŸŒªï¸', 'ðŸŒ«ï¸', 'ðŸŒ¬ï¸', 'ðŸŒ€', 'ðŸŒˆ', 'ðŸŒ‚', 'â˜‚ï¸', 'â˜”', 'â›±ï¸', 'âš¡', 'â„ï¸', 'â˜ƒï¸', 'â›„', 'â˜„ï¸', 'ðŸ”¥', 'ðŸ’§', 'ðŸŒŠ'],
    'cosmic': ['âœ¨', 'ðŸ’«', 'ðŸŒŸ', 'â­', 'ðŸŒ ', 'ðŸŒŒ', 'ðŸŒƒ', 'ðŸŒ†', 'ðŸŒ‡', 'ðŸŒ‰', 'ðŸŒŠ', 'ðŸŒ‹', 'ðŸ—»', 'ðŸ”ï¸', 'â›°ï¸', 'ðŸ•ï¸', 'ðŸ–ï¸', 'ðŸœï¸', 'ðŸï¸', 'ðŸª', 'ðŸ›¸', 'ðŸš€', 'ðŸ›°ï¸', 'ðŸŒ', 'ðŸŒŽ', 'ðŸŒ', 'ðŸ—ºï¸', 'ðŸ§­', 'â°', 'â±ï¸', 'â²ï¸', 'ðŸ•', 'ðŸ•‘', 'ðŸ•’', 'ðŸ•“', 'ðŸ•”', 'ðŸ••', 'ðŸ•–', 'ðŸ•—', 'ðŸ•˜', 'ðŸ•™', 'ðŸ•š', 'ðŸ•›', 'ðŸ•œ', 'ðŸ•', 'ðŸ•ž', 'ðŸ•Ÿ', 'ðŸ• ', 'ðŸ•¡', 'ðŸ•¢', 'ðŸ•£', 'ðŸ•¤', 'ðŸ•¥', 'ðŸ•¦', 'ðŸ•§']
}

# Composition operations
COMPOSITION_OPS = {
    'merge': {
        'description': 'Combine two glyphs into unified form',
        'examples': [
            ('â¤ï¸', 'âœ¨', 'ðŸ’–'),
            ('ðŸŒŸ', 'ðŸŒ™', 'ðŸŒ '),
            ('ðŸ˜Š', 'ðŸŒ¸', 'ðŸ¥°')
        ]
    },
    'swirl': {
        'description': 'Add rotational energy to glyph',
        'examples': [
            ('ðŸ’«', 'ðŸŒ€', 'âœ¨'),
            ('ðŸŒŠ', 'ðŸŒ€', 'ðŸŒªï¸'),
            ('â¤ï¸', 'ðŸŒ€', 'ðŸ’•')
        ]
    },
    'infuse': {
        'description': 'Infuse glyph with energy or emotion',
        'examples': [
            ('ðŸŒ¸', 'love', 'ðŸŒº'),
            ('â­', 'energy', 'ðŸŒŸ'),
            ('ðŸ˜', 'joy', 'ðŸ˜Š')
        ]
    },
    'warp': {
        'description': 'Transform through dimensional fold',
        'examples': [
            ('ðŸŒ', 'space', 'ðŸª'),
            ('ðŸ¦‹', 'time', 'âœ¨'),
            ('ðŸ’­', 'reality', 'ðŸŒŒ')
        ]
    }
}

# Semantic tags for glyphs
GLYPH_TAGS = {
    'â¤ï¸': ['love', 'heart', 'emotion', 'connection'],
    'âœ¨': ['sparkle', 'magic', 'energy', 'cosmic'],
    'ðŸŒŸ': ['star', 'bright', 'cosmic', 'special'],
    'ðŸŒ™': ['moon', 'night', 'cosmic', 'dream'],
    'ðŸŒ¸': ['flower', 'nature', 'beauty', 'gentle'],
    'ðŸ«¶': ['heart-hands', 'love', 'care', 'connection'],
    'ðŸ’«': ['dizzy', 'star', 'energy', 'motion'],
    'ðŸŒ€': ['spiral', 'vortex', 'energy', 'motion'],
    'ðŸ§ ': ['brain', 'mind', 'thought', 'consciousness'],
    'ðŸ‘ï¸': ['eye', 'see', 'perception', 'awareness'],
    'ðŸ”®': ['crystal-ball', 'magic', 'future', 'mystery'],
    'ðŸŒˆ': ['rainbow', 'color', 'hope', 'bridge'],
    'ðŸ’Ž': ['gem', 'crystal', 'precious', 'clarity'],
    'ðŸŒŠ': ['wave', 'water', 'flow', 'emotion'],
    'ðŸ”¥': ['fire', 'energy', 'passion', 'transform'],
    'ðŸ¦‹': ['butterfly', 'transform', 'beauty', 'change'],
    'ðŸŒº': ['hibiscus', 'flower', 'tropical', 'beauty'],
    'ðŸŽ­': ['masks', 'drama', 'emotion', 'duality'],
    'ðŸª': ['planet', 'cosmic', 'space', 'vast'],
    'ðŸŒŒ': ['galaxy', 'cosmic', 'infinite', 'mystery']
}


def generate_glyph_sequences(num_sequences: int = 1000) -> List[Dict]:
    """Generate natural glyph sequences"""
    sequences = []
    
    for _ in range(num_sequences):
        # Choose a category
        category = random.choice(list(EMOJI_CATEGORIES.keys()))
        emojis = EMOJI_CATEGORIES[category]
        
        # Generate sequence length (2-8 glyphs)
        seq_len = random.randint(2, 8)
        
        # Build sequence
        sequence = []
        for i in range(seq_len):
            if i == 0 or random.random() > 0.3:
                # New emoji
                sequence.append(random.choice(emojis))
            else:
                # Sometimes repeat or use related
                if random.random() > 0.5 and i > 0:
                    sequence.append(sequence[-1])  # Repeat
                else:
                    sequence.append(random.choice(emojis))
        
        # Create training example
        sequences.append({
            'sequence': ''.join(sequence),
            'category': category,
            'length': len(sequence)
        })
    
    return sequences


def generate_composition_data(num_examples: int = 500) -> List[Dict]:
    """Generate glyph composition training data"""
    compositions = []
    
    for _ in range(num_examples):
        # Choose operation
        op = random.choice(list(COMPOSITION_OPS.keys()))
        op_data = COMPOSITION_OPS[op]
        
        # Get example or generate new
        if random.random() > 0.5 and op_data['examples']:
            # Use known example
            input1, input2, output = random.choice(op_data['examples'])
            
            compositions.append({
                'instruction': f'<<compose glyph="{input1}" op="{op}" strength="{random.uniform(0.5, 1.0):.1f}">>',
                'input': input1,
                'operation': op,
                'strength': random.uniform(0.5, 1.0),
                'output': output,
                'description': f'{op} operation on {input1}'
            })
        else:
            # Generate new combination
            all_emojis = []
            for emojis in EMOJI_CATEGORIES.values():
                all_emojis.extend(emojis)
            
            input_glyph = random.choice(all_emojis)
            strength = random.uniform(0.3, 1.0)
            
            # Simple rule-based output (in real training, these would be human-annotated)
            if op == 'swirl':
                output = input_glyph + 'ðŸŒ€'
            elif op == 'infuse':
                output = input_glyph + 'âœ¨'
            elif op == 'warp':
                output = input_glyph + 'ðŸŒŒ'
            else:  # merge
                second_glyph = random.choice(all_emojis)
                output = input_glyph + second_glyph
            
            compositions.append({
                'instruction': f'<<compose glyph="{input_glyph}" op="{op}" strength="{strength:.1f}">>',
                'input': input_glyph,
                'operation': op,
                'strength': strength,
                'output': output,
                'description': f'{op} operation on {input_glyph} with strength {strength:.1f}'
            })
    
    return compositions


def generate_tag_data(num_examples: int = 300) -> List[Dict]:
    """Generate glyph to tag mapping data"""
    tag_data = []
    
    # Use known mappings
    for glyph, tags in GLYPH_TAGS.items():
        tag_data.append({
            'glyph': glyph,
            'tags': tags,
            'primary_tag': tags[0],
            'description': f'{tags[0]} glyph representing {", ".join(tags[1:])}'
        })
    
    # Generate additional mappings
    all_emojis = []
    for emojis in EMOJI_CATEGORIES.values():
        all_emojis.extend(emojis)
    
    used_glyphs = set(GLYPH_TAGS.keys())
    
    while len(tag_data) < num_examples:
        glyph = random.choice(all_emojis)
        if glyph in used_glyphs:
            continue
        
        # Generate plausible tags based on Unicode name
        try:
            unicode_name = unicodedata.name(glyph).lower()
            tags = unicode_name.split()
            
            # Filter and enhance tags
            tags = [t for t in tags if len(t) > 2 and t not in ['with', 'and', 'the']]
            
            if tags:
                tag_data.append({
                    'glyph': glyph,
                    'tags': tags[:4],  # Limit to 4 tags
                    'primary_tag': tags[0],
                    'description': f'{tags[0]} glyph'
                })
                used_glyphs.add(glyph)
        except:
            continue
    
    return tag_data[:num_examples]


def save_datasets(output_dir: Path):
    """Generate and save all datasets"""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Generate datasets
    print("Generating glyph sequences...")
    sequences = generate_glyph_sequences(1000)
    
    print("Generating composition data...")
    compositions = generate_composition_data(500)
    
    print("Generating tag data...")
    tags = generate_tag_data(300)
    
    # Save datasets
    datasets = {
        'glyph_sequences.jsonl': sequences,
        'glyph_compose.jsonl': compositions,
        'glyph_tags.jsonl': tags
    }
    
    for filename, data in datasets.items():
        filepath = output_dir / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            for item in data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        print(f"Saved {len(data)} examples to {filepath}")
    
    # Create dataset info
    info = {
        'datasets': {
            'sequences': {
                'file': 'glyph_sequences.jsonl',
                'count': len(sequences),
                'description': 'Natural glyph sequences for next-token prediction'
            },
            'composition': {
                'file': 'glyph_compose.jsonl',
                'count': len(compositions),
                'description': 'Glyph composition instructions and outputs'
            },
            'tags': {
                'file': 'glyph_tags.jsonl',
                'count': len(tags),
                'description': 'Glyph to semantic tag mappings'
            }
        },
        'total_examples': len(sequences) + len(compositions) + len(tags)
    }
    
    with open(output_dir / 'dataset_info.json', 'w') as f:
        json.dump(info, f, indent=2)
    
    print(f"\nTotal examples created: {info['total_examples']}")
    print(f"Datasets saved to: {output_dir}")


if __name__ == "__main__":
    # Create datasets
    save_datasets("data/processed")
    
    # Show sample data
    print("\n=== Sample Data ===")
    
    # Load and show samples
    with open("data/processed/glyph_sequences.jsonl", 'r') as f:
        print("\nSequence sample:")
        print(json.loads(f.readline()))
    
    with open("data/processed/glyph_compose.jsonl", 'r') as f:
        print("\nComposition sample:")
        print(json.loads(f.readline()))
    
    with open("data/processed/glyph_tags.jsonl", 'r') as f:
        print("\nTag sample:")
        print(json.loads(f.readline()))