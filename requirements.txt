# Core ML
torch>=2.0.0
transformers>=4.35.0
accelerate>=0.24.0
peft>=0.7.0  # For LoRA
datasets>=2.14.0
tokenizers>=0.15.0

# Gemma specific
sentencepiece>=0.1.99  # Gemma tokenizer

# Memory & Vector Search
faiss-cpu>=1.7.4  # Use faiss-gpu if CUDA available
numpy>=1.24.0
msgpack>=1.0.5  # For CID serialization

# Quantization
bitsandbytes>=0.41.0  # For INT4/INT8
onnx>=1.14.0
onnxruntime>=1.16.0

# Evaluation & Metrics
scikit-learn>=1.3.0
nltk>=3.8.0
rouge-score>=0.1.2

# API & Integration
fastapi>=0.104.0
uvicorn>=0.24.0
websockets>=12.0
pydantic>=2.4.0

# Monitoring
wandb>=0.15.0
tensorboard>=2.14.0
tqdm>=4.66.0

# Utils
pyyaml>=6.0
python-dotenv>=1.0.0
rich>=13.5.0  # Pretty printing
click>=8.1.0  # CLI

# Development
pytest>=7.4.0
black>=23.0.0
flake8>=6.1.0
mypy>=1.5.0
pre-commit>=3.4.0